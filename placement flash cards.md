>Links: [[misc]]

# Data Science
- Data Science is a broader field that involves the use of statistical, mathematical, and computational techniques to extract insights and knowledge from data. 
- The goal of data science is to uncover patterns, relationships, and trends in large and complex data sets, and use this information to inform business decisions, scientific research, and other areas. 
- Data Science typically involves working with big data, unstructured data, and involves developing predictive models using machine learning algorithms.

# data analysis
- Data Analytics, on the other hand, focuses more on the analysis and interpretation of data to draw insights that can inform business decisions. 
- Data Analytics is typically focused on a specific area of a business, such as sales or marketing, and involves working with structured data sets to answer specific questions. 
- Data Analytics can involve various statistical techniques to analyze data such as regression analysis, clustering analysis and more. 
- Data Analytics typically involves developing dashboards and reports to help business users make decisions based on data.

# SQL PLSQL
![[Pasted image 20230413130457.png]]

# EDA
EDA, or Exploratory Data Analysis, is an important initial step in data analysis. EDA involves the process of reviewing and analyzing data to identify patterns, relationships, and trends in the data. The main goal of EDA is to gain a better understanding of the data and to identify any potential issues or anomalies that may affect the results of subsequent analyses.

Some common techniques used in EDA include:

1. **Data visualization**: Using graphs, charts, and other visualizations to explore and analyze data.
2. **Descriptive statistics**: Using summary statistics such as mean, median, standard deviation, and percentiles to describe the distribution of the data.
3. **Data cleaning**: Identifying and correcting any errors, inconsistencies, or missing values in the data.
4. **Data transformation**: Converting data into a different format or scale to make it easier to analyze or visualize.
5. **Dimensionality reduction**: Reducing the number of variables in a dataset while preserving important information.
6. **Outlier detection**: Identifying and handling outliers or extreme values in the data.

# Big Data Tools
- **Hadoop** is an open-source framework for distributed storage and processing of large datasets using the MapReduce programming model.
- **Apache Spark** is an open-source data processing engine that can be used for large-scale data processing and analysis.
- **Hive** is a data warehousing and SQL-like query language for Hadoop that allows users to query and analyze large datasets stored in Hadoop.
- **Pig** is a platform for analyzing large datasets that consists of a high-level language for expressing data analysis programs and an infrastructure for evaluating these programs.
- **YARN** (Yet Another Resource Negotiator) is a resource management platform used to manage computing resources in clusters and schedule applications to run on top of Hadoop.
- **Sqoop** is a tool designed for efficiently transferring bulk data between Apache Hadoop and structured datastores such as relational databases.
- **NoSQL** (Not Only SQL) refers to a class of non-relational databases that are used to store and retrieve data in a way that doesn't require the use of a fixed schema like traditional relational databases.
- **Oozie** is a workflow scheduler system for managing Hadoop jobs.